<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>An Introduction to Machine Learning and Neural Networks</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
<section>
	<h2>A brief and quick history of chip design</h2>
	<h3>Tom Read Cutting</h3>
	</aside>
</section>
<section>
	<h3>We will cover:</h3>
	<ol>
		<li>The fetch-execute cycle and Von Neumann architecture.</li>
		<li>Moore's law.</li>
		<li>A brief (and incomplete) history of CPU design.</li>
		<li>Implications for you.</li>
	</ol>
</section>
<section>
	<p>NOTE: Things will move quickly! (Still may not be able to cover everything).</p>
	<p>Do not hesitate to interrupt and ask questions</p>
	<p class="fragment">Very dynamic, will be asking you questions as well!</p>
</section>
<section>
	<h3>What is a computer chip?</h3>
	<p>

		A piece of material made with silicon that consists of transistors enabling computations to be
		performed when provided with an electric current and inputs (as of 2019).

	</p>
</section>

<section>
	<section>
		<h3>What are we aiming for?</h3>
	</section>

	<section>
		<h3>The fetch-execute cycle</h3>
		<ol>
			<li>Grab instruction at PC address.</li>
			<li>Decode instruction.</li>
			<li>Execute instruction.</li>
			<li class="fragment">Repeat.</li>
		</ol>
	</section>

	<section>
		<h3>The Von Neumann Architecture</h3>
		<img width="600" src="img/VonNeumann.png" alt="Diagram showing the Von Neumann architecture" />
		<p>Most chips use the Von Neumann architecture, so this is the high level mental model we will use.</p>
	</section>

	<section>
		<h3>A note on alternatives, the Harvard Architecture:</h3>
		<img width="550" src="img/Harvard.png" alt="Diagram showing the Harvard architecture" />
		<p>Used in some custom chips, can you see the benefits of this? The downsides? We will come back to this.</p>
	</section>
</section>

<section>
	<section>
		<h3>What allows chips to improve?</h3>
	</section>
	<section>
		<h3>In two words: Moore's Law</h3>
	</section>
	<section>
		<h3>
			What is Moore's law?
		</h3>
		<img width="500" src="img/MooreLaw.png" alt="A diagram of moore's law in the real world"/>
		<p>Gordon Moore, CEO of Intel: "The complexity for minimum component costs has increased at a rate of roughly a factor of two per year."</p>
	</section>
	<section>
		<h3>ASIDE: Moore's Law is not a 'real' law</h3>
		<p>Heavy debates about it being a self-fulfilling prophecy.</p>
	</section>
	<section>
		<h3>Why does this allow for faster chips?</h3>
		<ul>
			<li>We take it as a given, but why?</li>
			<li>What is CPU speed anyway? Are they just clock cycles?</li>
			<li>What about multi-core CPUs?</li>
			<li>What about the instructions themselves?</li>
			<li>This is where chip design comes in.</li>
		</ul>
	</section>
</section>

<section>
	<section>
		<h3>Designing an old Von-Neumann CPU</h3>
	</section>
	<section>
		<h3>What are our constraints?</h3>
		<ul>
			<li>Low transistor density.</li>
			<li>Low amount of memory.</li>
		</ul>
	</section>
	<section>
		<h3>Implication of constraints</h3>
		<ul>
			<li>Distance between transistors high (increased time of information transition) -> low clock frequencies.</li>
		</ul>
	</section>
	<section>
	<h3>The CISC CPU</h3>
	<p>Complex instruction set computer</p>
	<ul>
		<li>Many, complicated instructions.</li>
		<li>Variable length encoding.</li>
		<li>Simple(r) chip design.</li>
		<li>Single-Core.</li>
		<li>Always-addressable pool of memory.</li>
	</ul>
	<p class="fragment">What trade-offs are we making here?</p>
	<aside class="notes">Why do we want this? What could the downsides be? Why do the constraints allow us to do this?</aside>
	</section>
</section>
<section>
	<section><h3>Evolving CPUs</h3><p>A tale of new possibilities and evolving constraints</p></section>
	<section>
		<h3>Three big stories:</h3>
		<ul>
			<li>Moore's Law</li>
			<li>Memory Size</li>
			<li>The Operating System behemoth</li>
		</ul>
	</section>
	<section>
		<h3>How do the constraints change?</h3>
		<ul>
			<li>Higher transistor density.</li>
			<li>More heat generation.</li>
			<li>Multitasking desired.</li>
		</ul>
	</section>
	<section>
		<h3>Brief overview OS support</h3>
		<ul>
			<li>Virtual paging.</li>
			<li>Time-slicing.</li>
			<li>Privileged execution.</li>
			<li>Generic BUSes.</li>
		</ul>
		<p>We can cover these in depth another time...</p>
	</section>
	<section>
		<h3>Now onto the good stuff...</h3>
		<ol>
			<li>Instruction pipelining</li>
			<li>RISC architectures</li>
			<li>Register file support</li>
			<li>Branch prediction</li>
			<li>Caching</li>
			<li>Multi-core support</li>
		</ol>
		<p>Admittedly a lot to cover! So brief explanations of how they work and analyses of the tradeoffs they make.</p>
	</section>
</section>
<section>
	<section>
		<h3>Instruction pipelining</h3>
		<img width="400" src="img/pipeline.png" alt="A diagram showing pipelining"/>
		<p>Pipelining is a great way to improve clock speeds, why?</p>
	</section>
	<section>
		<h3>Instruction pipelining tradeoffs:</h3>
		<ul class="fragment">
			<li>✔️ Less to do each cycle: shorter cycles.</li>
			<li>❌ Are limited by the longest stage of the pipeline.</li>
			<li>❌ Higher Frequencies = More Heat.</li>
			<li>❌ What about branching?</li>
			<li>❌ What if a stage takes +1 cycles?</li>
			<li>❌ More silicon required.</li>
		</ul>
		<p class="fragment">All the other techniques essentially exist to help mitigate the effects of pipelining, although it is still an important part of CPU architectures today.</p>
	</section>
</section>
<section>
	<section>
		<h3>Register file support</h3>
		<p>Have on-chip memory for storing data which instructions can refer to.</p>
	</section>
	<section>
		<h3>Register file support tradeoffs</h3>
		<ul class="fragment">
			<li>✔️ Shorter instructions if operating on same data multiple times.</li>
			<li>✔️ Don't have to fetch/store in main memory every instruction.</li>
			<li>❌ Need more silicon to for data storage.</li>
			<li>❌ Hard to optimise register usage correctly.</li>
			<li>❌ Transparent to programmer: new registers won't improve old programs.</li>
		</ul>
		<p class="fragment">Modern CPUs can actually use <em>register renaming</em> to have virtual registers.</p>
	</section>
</section>
<section>
	<section>
		<h3>RISC Architecture</h3>
		<p>Reduced instruction set computer</p>
		<p>The goal is to instructions simpler, and therefore easier to decode.</p>
	</section>
	<section>
		<h3>RISC tradeoffs</h3>
		<ul class="fragment">
			<li>✔️ Fewer cycles per instruction = shorter pipelines.</li>
			<li>❌ More memory for instructions.</li>
			<li>❌ Can no longer have specialised hardware for specialised instructions.</li>
			<li>❌ Must load data into register files before use.</li>
		</ul>
	</section>
</section>
<section>
	<section>
		<h3>Branch prediction</h3>
		<p>The goal is predict which branch the code will take, reducing the changes of a pipeline "flush".</p>
	</section>
	<section>
		<h3>How does it work at a high level?</h3>
		<p>Program Counter (PC) indexes a table of data containing historical information about the execution.</p>
		<img width="600" src="img/branchpred.png" alt="diagram of branch prediction" />
		<p>Can't be complex!</p>
	</section>
	<section>
		<h3>Types of branch prediction</h3>
		<ul>
			<li>n-bit saturating counters.</li>
			<li>Global branch prediction.</li>
			<li>Tournament branch prediction.</li>
			<li class="fragment">And many more!</li>
		</ul>
	</section>
	<section><h3>Branch prediction tradeoffs</h3>
		<ul class="fragment">
			<li>✔️ Reduces chance of pipeline flush.</li>
			<li>❌ Adds a lot of complexity.</li>
			<li>❌ What if two PC's index same location in table? (Think hash table collision).</li>
		</ul>
	</section>
</section>
<section>
	<section>
		<h3>Caching</h3>
		<p>Problem: We are limited by the speed of light.</p>
		<p>Clock cycles have gone up, memory access latency hasn't changed much.</p>
		<p>DRAM Access is 240 cycles!</p>
	</section>
	<section>
		<h3>What does the cache bring?</h3>
		<ol>
			<li>Register File Access: 1 cycle</li>
			<li>L1 CACHE hit: 4 cycles</li>
			<li>L2 CACHE hit: 10 cycles</li>
			<li>L3 CACHE hit: 40 cycles</li>
			<li>DRAM Access: 240 cycles</li>
		</ol>
	</section>
	<section>
		<h3>In human terms...</h3>
		<ol>
			<li>Register File Access: 1 day</li>
			<li>L1 CACHE hit: 4 days</li>
			<li>L2 CACHE hit: ~one week</li>
			<li>L3 CACHE hit: ~one month</li>
			<li>DRAM Access: ~2/3rds of a year</li>
		</ol>
	</section>
	<section>
			<h3>On the L1 cache...</h3>
			<p>L1 caches are often separated into separate 'instruction' and 'data' caches. What does this remind you of?</p>
		</section>
	<section><h3>Caching tradeoffs</h3>
		<ul class="fragment">
			<li>✔️ Reduce memory access cost</li>
			<li>✔️ Invisible to programmer</li>
			<li>❌ Invisible to programmer</li>
			<li>❌ Very visible to programmer</li>
		</ul></section>
</section>
<section>
	<section>
		<h3>Multi-core support</h3>
		<p>Why not have multiple CPUs on the same chip?</p>
	</section>
	<section><h3>Multi-core support tradeoffs</h3>
		<ul class="fragment">
			<li>✔️ Lower clock speeds heat.</li>
			<li>✔️ Simpler pipelines (and all the problems that come with them).</li>
			<li>❌ Added complexity.</li>
			<li>❌ Race conditions.</li>
			<li>❌ Cache coherency.</li>
			<li>❌ May need more I/O.</li>
			<li>❌ Too many to count...</li>
		</ul></section>
</section>
<section>
	<section>
	<h3>Bringing it all together, we have covered:</h3>
	<ol>
		<li>The physics layer.</li>
		<li>The fetch-execute cycle and Von Neumann architecture.</li>
		<li>Moore's law.</li>
		<li>A brief (and incomplete) history of CPU design.</li>
		<li class="fragment">Implications for you?</li>
	</ol>
	</section>
	<section>
		<h3>Why this is important (1):</h3>
		<p>The design of hardware has a *massive* effect on the software that runs on it!</p>
		<p>Increased design complexity has massively increased the importance, prevalence and necessity of software abstractions.</p>
	</section>
	<section>
	<h3>Why this is important (2):</h3>
	<p>Yet, almost paradoxically, complex designs means that subtle changes can have massive effects on functionality and performance!
	</p>
	<p>However, powerful hardware can mitigate the performance impact of application in isolation.</p>
	<p>Yet, we are asking our computers to multi-task more-and-more every day! The sum-total can still be quite bad!</p>
	</section>
	<section>
		<h3>Final points</h3>
		<ol>
		<li>I hope you found this interesting.</li>
		<li>Hardware design is important.</li>
		<li>Multi-core is here to stay, we need to learn how to use it.</li>
		<li>Memory access-patterns are a big deal, be cache-friendly!</li>
		</ol>
	</section>
</section>
<section>
	<h3>Future hardware talk possibilities</h3>
	<ol>
		<li>Any topic here, but in depth.</li>
		<li>Cache design.</li>
		<li>Cache coherency.</li>
		<li>SoC design.</li>
		<li>GPU design.</li>
		<li>OS support.</li>
		<li>The physics of silicon chips.</li>
	</ol>
</section>
<section>
	<h3>Thank you! Any questions?</h3>
	<p>Although shallow and brief, hope this gives you an idea about how CPUs can be designed and optimised.</p>
</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/math/math.js', async: true }
				]
			});
		</script>
	</body>
</html>

<!--
	Image references:
	(TODO, add them properly)
	Harvard Arch: https://en.wikipedia.org/wiki/Harvard_architecture#/media/File:Harvard_architecture.svg
	VOn Neumann Arch: https://en.wikipedia.org/wiki/Von_Neumann_architecture#/media/File:Von_Neumann_Architecture.svg
	Moore's Law: https://en.wikipedia.org/wiki/Moore%27s_law#/media/File:Moore%27s_Law_Transistor_Count_1971-2016.png
	Pipeline: https://en.wikipedia.org/wiki/Instruction_pipelining#/media/File:Pipeline,_4_stage.svg
	BRANCH PRED: https://en.wikipedia.org/wiki/File:Two-level_branch_prediction.svg#/media/File:Two-level_branch_prediction.svg
	Cache Source: https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory
-->
